%!TEX root = ../dokumentation.tex

\chapter{Validierung}

\section{Vorgehensweise}
	\subsection{Nutzung von Starexec und TPTP}
		Zur Validierung der Arbeit werden Performancetests durchgeführt, die die Effizienz verschiedener Strategien vergleichbar machen.	Die Beweissuche wird auf der Hardware von Starexec durchgeführt, um eine möglichst konstante Rechenleistung zu haben. Wie in Sektion \ref{section:2StarexecTPTP} beschrieben, setzt sich ein Job aus einer Menge von Beweiser-Konfigurationen und einer Menge von Problemen zusammen. 
		
		Der verwendete Beweiser ist eine ZIP-Datei mit den Python-Dateien von PyRes. Er enthält die fertige Implementierung der SOS-Strategien. Konfigurationen sind ebenfalls in der ZIP-Datei enthalten und werden durch ein Text-Datei spezifiziert. Die Datei enthält den Befehl zum Ausführen von PyRes mit angegebenen Eingabeparametern. Diese Parameter geben vor, welche Optimierungen durchgeführt werden, beispielsweise Literalselektion, SOS-Strategie, SOS-Ratio usw.
		
		Die Probleme, auf die die Beweissuche angewandt wird, kommen von TPTP, einem Benchmark, der sich aus etwa 24000 Problemdateien zusammensetzt (siehe Sektion \ref{section:2StarexecTPTP}.
		
		Bei der Konfiguration eines Starexec-Jobs kann eine	maximale Rechenzeit angegeben werden, die ein Paar aus Problem und Konfiguration zugewiesen bekommt. Findet PyRes innerhalb dieser Zeit keine Lösung für das Problem, wird die Suche abgebrochen. Für alle Jobs sollte die maximale Rechenzeit gleich festgelegt sein, um die Starexec-Ergebnisse mehrerer Jobs vergleichbar zu machen. Der Standard-Wert bei Starexec liegt bei 300 Sekunden, der genaue Wert wurde für diese Arbeit auf 20 Sekunden herabgesetzt.
		
		Eine geringere Rechenzeit führt zwar zu weniger gelösten Problemen, aber die Jobs nehmen weniger Zeit in Anspruch. Da die Anzahl der gelösten Probleme in Abhängigkeit zur Zeit weniger als linear zunimmt, kann man davon ausgehen, dass es nur wenig Beweise gibt, die nach 20 Sekunden noch gefunden werden. Aus diesem Grund wurde der Vorteil der schnelleren Berechnungszeit höher gewichtet.
	
	\subsection{Zu analysierende Konfigurationen}
		Es wurden 3 SOS-Strategien implementiert und es gibt die Möglichkeit keine SOS-Strategie einzusetzen. Diese vier Möglichkeiten lassen sich mit Konzept 1 oder mit Konzept 2 kombinieren und können jeweils mit oder ohne Literalselektion durchgeführt werden. In der Theorie ergeben sich damit 16 Kombinationen, von denen nicht alle vollständig sind und es redundante Konfigurationen gibt. Folgende Tabelle zeigt eine Übersicht mit den möglichen Konfigurationen (siehe Tabelle \ref{table:possibleConfigs}). 		
		
		Wenn keine SOS-Strategie angegeben wird, dann erstellt PyRes standardmäßig ein Objekt der Klasse NoSos als Platzhalter (siehe Sektion \ref{section:4.1}). Für die Konfiguration ohne SOS sind Konzept 1 und 2 gleichbedeutend, da in beiden Fällen keine Klausel als Teil des SOS markiert wird und auch keine Klausel anfangs in die verarbeitete Klauselmenge einsortiert wird. Die Beweissuche ist mit und ohne Literalselektion vollständig. Die Ergebnisse dieser Konfigurationen werden als Referenzwerte für die spätere Validierung herangezogen.
		
		Die drei SOS-Strategien können mit beiden Konzepten kombiniert werden, allerdings ist Konzept 1 in Verbindung mit Literalselektion unvollständig. In Konzept 2 kann mit der Option "R" zusätzlich ein ganzzahliges Verhältnis angegeben werden, das die Verarbeitung von SOS und Nicht-SOS-Klauseln bestimmt. Für die Wahl dieses Wertes wurde sich für eine logarithmische Abstufung entschieden, da sie einen größeren Wertebereich abdeckt.
		
		
		\begin{table}[h]
			\centering
			\begin{tabular}{|c|c|c|c|c|c|}
				\hline
				& & \multicolumn{2}{c|}{SOS-Konzept 1} & \multicolumn{2}{c|}{SOS-Konzept 2} \\
				& & \multicolumn{2}{c|}{(Nicht-SOS $\rightarrow$ processed)} & \multicolumn{2}{c|}{(Priorisierte Verarbeitung)}  \\
				\cline{3-6}
				& & keine Literalsel. & Literalsel. & keine Literalsel. & Literalsel. \\
				\hline\hline
				 \multirow{4}{*}{\rotatebox[origin=c]{90}{SOS-Strategie}} & NoSos & \checkmark & \checkmark & redundant & redundant \\
				\cline{2-6}
				& Conjecture & \checkmark & unvolls. & \checkmark & \checkmark \\
				\cline{2-6}
				& OnlyPosLit & \checkmark & unvolls. & \checkmark & \checkmark \\
				\cline{2-6}
				& OnlyNegLit & \checkmark & unvolls. & \checkmark & \checkmark \\
				\hline
			\end{tabular}
			\label{table:possibleConfigs}
			\caption{Mögliche Konfigurationen für Performancetests. Unvollständige und redundante Konfigurationen werden nicht durchgeführt. Bei Konzept 2 kann die Konfiguration zusätzlich mit dem Verhältnis $R$ variiert werden.}
		\end{table}

	
	\subsection{Zu analysierende Größen}
	
	Wenn PyRes ein Problem innerhalb der angegebenen Zeit lösen kann, gibt es den bewiesenen Status des Problems in einer Ergebnisdatei aus. Des weiteren werden Informationen über die Beweissuche ausgegeben, zum Beispiel die Anzahl der berechneten Resolventen und die Zeit, die für die Beweissuche benötigt wurde.
	
	Folgende Größen können zur Performance-Analyse herangezogen werden.
	\begin{itemize}
		\item Die Anzahl der insgesamt gelösten Probleme von allen etwa 24000 TPTP Problemen macht eine Aussage über die Effizienz einer Konfiguration. Zusätzlich kann zwischen dem Status der Probleme (Erfüllbarkeit / Unerfüllbarkeit) differenziert werden, da eine Konfiguration, die schneller einen Widerspruch findet, nicht zwangsweise schneller die Erfüllbarkeit belegt.
		
		\item Die benötigte Zeit der gelösten Probleme kann zur Analyse herangezogen werden. Es kann sowohl die durchschnitte Zeit aller gelösten Probleme betrachtet werden, als auch der Graph, der den Verlauf der gelösten Probleme in Abhängigkeit zu Zeit darstellt.
		
		Da es vorkommt, dass zwei Konfigurationen nicht exakt die gleichen Probleme lösen, kann der Vergleich zwischen den Rechenzeiten verfälscht werden. Eine effizientere Konfiguration könnte beispielsweise viele Probleme schneller lösen, als eine ineffizientere Konfiguration. Die effizientere Konfiguration würde auch schwierige Probleme lösen, die die ineffizientere nicht löst. Auf diese Weise wird die durchschnittlich benötigte Rechenzeit der effizienten Konfiguration durch die hohe Rechnezeit der schwierigeren Probleme nach unten gezogen.
		
		Eine Lösung dafür ist, nicht alle gelösten Probleme in die Analyse einfließen zu lassen, sondern nur die Schnittmenge der gelösten Probleme unter allen Konfigurationen.
		
		\item Neben der Rechenzeit können die anderen Ergebnisgrößen wie berechnete Resolventen, berechnete Faktoren berücksichtigt werden. Auch hier sollten zum Vergleich zweier Konfigurationen lediglich die Probleme betrachtet werden, die unter allen Konfigurationen gelöst werden. Es ist davon auszugehen, dass diese Größen stark mit der benötigten Rechenzeit korrelieren.
		
		\item Eine weitere Möglichkeit, zwei Konfigurationen zu vergleichen, ist, die Probleme im direkten Vergleich in Bezug zu setzen. Anstatt wie oben genannt, alle Rechenzeiten einer Konfiguration mit allen Rechenzeiten der anderen Konfigurationen zu vergleichen, werden für jedes Problem einzeln die Rechenzeiten verglichen. Somit kann für jedes einzelne Problem eine prozentualer Abweichung errechnet werden. Über alle Probleme kann dann ein Mittelwert gebildet werden. 
	\end{itemize}
	\subsection{Prüfung widersprüchlicher Ergebnisse}
		Für alle StarExec-Ergebnisse kann geprüft werden, ob Widersprüche zwischen dem gefundenen Status und dem tatsächlichen Status vorliegen, da in jedem Problem der tatsächliche Status des Problems angegeben ist. ob  Ein Widerspruch liegt dann vor, wenn ein Problem in einer Konfiguration als unerfüllbar eingestuft wurde, aber in Wirklichkeit erfüllbar ist, oder vice versa. In solch einem Fall ist der Beweiser fehlerhaft, vorausgesetzt der angegebene tatsächliche Status ist korrekt. Alle Ergebnisse dieses Kapitels wurden geprüft und sind widerspruchsfrei. Das heißt jedoch nicht, dass die Implementierung keine Fehler enthält.

\section{Ergebnisse}
	\subsection{Performancevergleich der SOS-Strategien}
	 	Als erstes wird SOS-Konzept 1 (Nicht-SOS $\rightarrow$ processed) analysiert. 
			

	
	\subsection{Vergleich der beiden SOS-Konzepte}
	\subsection{SOS-Strategie mit anderen Optimierungen}
	
\section{Bewertung}

Ergebnis Performance,
eventuell Unit Tests,
Erweiterungsmöglichkeiten,
Kompatibilität mit anderen Erweiterungen (geordnete Resolution, Literalselektion),
Verständlichkeit der Implementierung,

